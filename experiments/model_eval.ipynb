{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coli_mask_frame_1.tiff paired with coli_mask_frame_1.tiff\n",
      "coli_mask_frame_10.tiff paired with coli_mask_frame_10.tiff\n",
      "coli_mask_frame_101.tiff paired with coli_mask_frame_101.tiff\n",
      "coli_mask_frame_109.tiff paired with coli_mask_frame_109.tiff\n",
      "coli_mask_frame_132.tiff paired with coli_mask_frame_132.tiff\n",
      "coli_mask_frame_165.tiff paired with coli_mask_frame_165.tiff\n",
      "coli_mask_frame_166.tiff paired with coli_mask_frame_166.tiff\n",
      "coli_mask_frame_205.tiff paired with coli_mask_frame_205.tiff\n",
      "coli_mask_frame_223.tiff paired with coli_mask_frame_223.tiff\n",
      "coli_mask_frame_232.tiff paired with coli_mask_frame_232.tiff\n",
      "coli_mask_frame_274.tiff paired with coli_mask_frame_274.tiff\n",
      "coli_mask_frame_56.tiff paired with coli_mask_frame_56.tiff\n",
      "mabs_img_01.tiff paired with mabs_img_01.tiff\n",
      "mabs_img_02.tiff paired with mabs_img_02.tiff\n",
      "mabs_img_03.tiff paired with mabs_img_03.tiff\n",
      "mabs_img_04.tiff paired with mabs_img_04.tiff\n",
      "mabs_img_05.tiff paired with mabs_img_05.tiff\n",
      "mabs_img_06.tiff paired with mabs_img_06.tiff\n",
      "mabs_img_07.tiff paired with mabs_img_07.tiff\n",
      "mabs_img_08.tiff paired with mabs_img_08.tiff\n",
      "mabs_img_09.tiff paired with mabs_img_09.tiff\n",
      "mabs_img_10.tiff paired with mabs_img_10.tiff\n",
      "mabs_img_11.tiff paired with mabs_img_11.tiff\n",
      "mabs_img_12.tiff paired with mabs_img_12.tiff\n",
      "mabs_img_13.tiff paired with mabs_img_13.tiff\n",
      "mabs_img_14.tiff paired with mabs_img_14.tiff\n",
      "mabs_img_15.tiff paired with mabs_img_15.tiff\n",
      "mabs_img_16.tiff paired with mabs_img_16.tiff\n",
      "mabs_img_17.tiff paired with mabs_img_17.tiff\n",
      "mabs_img_18.tiff paired with mabs_img_18.tiff\n",
      "mabs_img_19.tiff paired with mabs_img_19.tiff\n",
      "mabs_img_20.tiff paired with mabs_img_20.tiff\n",
      "mabs_img_21.tiff paired with mabs_img_21.tiff\n",
      "mabs_img_22.tiff paired with mabs_img_22.tiff\n",
      "mabs_img_23.tiff paired with mabs_img_23.tiff\n",
      "mabs_img_24.tiff paired with mabs_img_24.tiff\n",
      "mabs_img_25.tiff paired with mabs_img_25.tiff\n",
      "mabs_img_26.tiff paired with mabs_img_26.tiff\n",
      "mabs_img_27.tiff paired with mabs_img_27.tiff\n",
      "mabs_img_28.tiff paired with mabs_img_28.tiff\n",
      "mabs_img_29.tiff paired with mabs_img_29.tiff\n",
      "mabs_img_30.tiff paired with mabs_img_30.tiff\n",
      "mabs_img_31.tiff paired with mabs_img_31.tiff\n",
      "mabs_img_32.tiff paired with mabs_img_32.tiff\n",
      "mabs_img_33.tiff paired with mabs_img_33.tiff\n",
      "mabs_img_34.tiff paired with mabs_img_34.tiff\n",
      "mabs_img_35.tiff paired with mabs_img_35.tiff\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from semantic_bac_segment.segmentator import Segmentator\n",
    "from semantic_bac_segment.model_loader import model_loader\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Get images\n",
    "path_images='../../Semantic_bac_segment/data/source_norm'\n",
    "path_masks='../../Semantic_bac_segment/data/masks_cleaned'\n",
    "image_files = [os.path.join(path_images, file) for file in os.listdir(path_images) if file.endswith('.tiff')]\n",
    "mask_files = [os.path.join(path_masks, file) for file in os.listdir(path_masks) if file.endswith('.tiff')]\n",
    "\n",
    "image_files.sort()\n",
    "mask_files.sort()\n",
    "\n",
    "max_width, max_height=2400, 2400\n",
    "\n",
    "for image_path, mask_path in zip(image_files, mask_files):\n",
    "\n",
    "    print(f'{os.path.basename(image_path)} paired with {os.path.basename(mask_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_1.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_10.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_101.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_109.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_132.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_165.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_166.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_205.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_223.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_232.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_274.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/coli_mask_frame_56.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_01.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_02.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_03.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_04.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_05.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_06.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_07.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_08.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_09.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_10.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_11.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_12.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_13.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_14.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_15.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_16.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_17.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_18.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_19.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_20.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_21.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_22.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_23.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_24.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_25.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_26.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_27.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_28.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_29.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_30.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_31.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_32.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_33.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_34.tiff\n",
      "../../Semantic_bac_segment/data/source_norm/mabs_img_35.tiff\n",
      "Image stack shape: (47, 2400, 2400)\n",
      "Mask stack shape: (47, 2400, 2400)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_width, max_height=2400, 2400\n",
    "\n",
    "padded_images = []\n",
    "padded_masks = []\n",
    "original_dimensions = {}\n",
    "\n",
    "for image_path, mask_path in zip(image_files, mask_files):\n",
    "    print(image_path)\n",
    "    image_name=os.path.basename(mask_path)\n",
    "    image = tifffile.imread(image_path)\n",
    "    mask = tifffile.imread(mask_path)\n",
    "\n",
    "    height, width = image.shape\n",
    "    original_dimensions[image_name] = (height, width)\n",
    "\n",
    "    pad_height = max_height - height\n",
    "    pad_width = max_width - width\n",
    "    \n",
    "    # Pad the image with zeros\n",
    "    padded_image = np.pad(image, ((0, pad_height), (0, pad_width)), mode='symmetric')\n",
    "    padded_images.append(padded_image)\n",
    "    \n",
    "    # Pad the mask with zeros\n",
    "    padded_mask = np.pad(mask, ((0, pad_height), (0, pad_width)), mode='symmetric')\n",
    "    padded_mask = padded_mask.astype(mask.dtype)  # Ensure the padded mask has the same data type as the original mask\n",
    "\n",
    "    padded_masks.append(padded_mask)\n",
    "\n",
    "# Convert the padded images and masks to stacks\n",
    "image_stack = np.stack(padded_images)\n",
    "mask_stack = np.stack(padded_masks)\n",
    "\n",
    "# Print the shape of the stacks\n",
    "print(\"Image stack shape:\", image_stack.shape)\n",
    "print(\"Mask stack shape:\", mask_stack.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask stack shape = (47, 1, 2400, 2400), image stack shape (47, 1, 2400, 2400)\n"
     ]
    }
   ],
   "source": [
    "image_stack=np.expand_dims(image_stack, axis=1)\n",
    "mask_stack=np.expand_dims(mask_stack, axis=1)\n",
    "\n",
    "print(f'mask stack shape = {mask_stack.shape}, image stack shape {image_stack.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('../results/top_models3/MonaiUnet-binary-top-4_best_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-4_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-3_best_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-3_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-3_final_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-3_final_config.json'),\n",
       " ('../results/top_models3/atomai_unet-binary-top-1_final_model.pth',\n",
       "  '../results/top_models3/atomai_unet-binary-top-1_final_config.json'),\n",
       " ('../results/top_models3/base_unet-binary-top-4_final_model.pth',\n",
       "  '../results/top_models3/base_unet-binary-top-4_final_config.json'),\n",
       " ('../results/top_models3/base_unet-binary-top-5_final_model.pth',\n",
       "  '../results/top_models3/base_unet-binary-top-5_final_config.json'),\n",
       " ('../results/top_models3/base_unet-binary-top-5_best_model.pth',\n",
       "  '../results/top_models3/base_unet-binary-top-5_best_config.json'),\n",
       " ('../results/top_models3/atomai_unet-binary-top-1_best_model.pth',\n",
       "  '../results/top_models3/atomai_unet-binary-top-1_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-4class-4_final_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-4class-4_final_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-4class-4_best_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-4class-4_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-4class-3_final_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-4class-3_final_config.json'),\n",
       " ('../results/top_models3/base_unet-binary-top-4_best_model.pth',\n",
       "  '../results/top_models3/base_unet-binary-top-4_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-res4_final_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-res4_final_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-biasdrop.3-3_best_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-biasdrop.3-3_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-4class-3_best_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-4class-3_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-biasdrop3_best_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-biasdrop3_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-res4_best_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-res4_best_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-bias3_final_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-bias3_final_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-biasdrop3_final_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-biasdrop3_final_config.json'),\n",
       " ('../results/top_models3/MonaiUnet-binary-top-bias3_best_model.pth',\n",
       "  '../results/top_models3/MonaiUnet-binary-top-bias3_best_config.json')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_folder='../results/top_models3'\n",
    "models_dict = []\n",
    "for file in os.listdir(results_folder):\n",
    "    if file.endswith('_model.pth'):\n",
    "        model_path = os.path.join(results_folder, file)\n",
    "        config_path = os.path.join(results_folder, file.replace('_model.pth', '_config.json'))\n",
    "\n",
    "        # Check if the corresponding config file exists\n",
    "        if os.path.exists(config_path):\n",
    "            # Add the model and its configuration to the dictionary\n",
    "            models_dict.append((model_path, config_path))\n",
    "        else:\n",
    "            print(f\"Warning: Config file not found for model {file}\")\n",
    "\n",
    "models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from semantic_bac_segment.utils import get_device\n",
    "for i, params_i in enumerate(models_dict):\n",
    "  try:\n",
    "    with open(params_i[1]) as f:\n",
    "      model_param = json.load(f)\n",
    "      model_i=model_loader(model_param, get_device(), weights=params_i[0])\n",
    "  except Exception as e:\n",
    "    print(f\"Error loading model {params_i[0]}: {e}\")\n",
    "    models_dict.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../results/top_models3/MonaiUnet-binary-top-3_best_model.pth',\n",
       " '../results/top_models3/MonaiUnet-binary-top-3_best_config.json')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_stack_binary=np.where(mask_stack > 100, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../results/top_models3/MonaiUnet-binary-top-biasdrop3_final_model.pth',\n",
       " '../results/top_models3/MonaiUnet-binary-top-biasdrop3_final_config.json')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ../results/top_models/top_models2/MonaiUnet-4class-top-3_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "from semantic_bac_segment.utils import get_device\n",
    "i=np.random.choice(len(models_dict), size=1, replace=False)\n",
    "\n",
    "device=get_device()\n",
    "pair_i = models_dict[int(-2)]\n",
    "with open(pair_i[1]) as f:\n",
    "#with open(config_path) as f:\n",
    "    model_param = json.load(f)\n",
    "    model_i=model_loader(model_param, device)\n",
    "print(f'Evaluating model {pair_i[-2]}')\n",
    "\n",
    "segmentator = Segmentator(pair_i[0], model_graph=model_i, patch_size=256, overlap_ratio=0.25, half_precision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9995777606964111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santiago/switchdrive/boeck_lab_projects/Semantic_bac_segment/experiments/../src/semantic_bac_segment/segmentator.py:186: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9979519248008728\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9997904300689697\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9976047873497009\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9999244809150696\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9999014735221863\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998800158500671\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.999390721321106\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9997673630714417\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998233318328857\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9985097050666809\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9994929432868958\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998148679733276\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9999076128005981\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998750686645508\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998040199279785\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998152852058411\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.999900758266449\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9999573826789856\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998697638511658\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998799562454224\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9979702830314636\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9999333620071411\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9999604821205139\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9981414675712585\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9991284012794495\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998728036880493\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.999508261680603\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9996387958526611\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9987924695014954\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998136162757874\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9995280504226685\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9996429681777954\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9991687536239624\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9994627833366394\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9993827939033508\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9992378354072571\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9992002844810486\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9994078278541565\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9999767541885376\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9992794394493103\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998139142990112\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998780488967896\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9998152852058411\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9994633793830872\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9991124272346497\n",
      "shape image (1, 2400, 2400)\n",
      "mean image 0.9999750256538391\n"
     ]
    }
   ],
   "source": [
    "from monai.data import ArrayDataset\n",
    "from monai.inferers import SlidingWindowInferer\n",
    "from monai.metrics import ConfusionMatrixMetric\n",
    "from semantic_bac_segment.utils import normalize_percentile, empty_gpu_cache, tensor_debugger\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def scale_image(image):\n",
    "    \"\"\"\n",
    "    Scale an image to the range [0, 1].\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Scaled image.\n",
    "    \"\"\"\n",
    "    min_value = np.min(image)\n",
    "    max_value = np.max(image)\n",
    "    scaled_image = (image - min_value) / (max_value - min_value)\n",
    "    return scaled_image\n",
    "\n",
    "device=get_device()\n",
    "# Create an instance of the Inferer\n",
    "inferer = SlidingWindowInferer(\n",
    "    device=device,\n",
    "    roi_size=(256, 256),  # Specify the desired output size\n",
    "    overlap=.1\n",
    ")\n",
    "\n",
    "# Initialize variables to store the predicted and ground truth labels\n",
    "predicted_labels = []\n",
    "ground_truth_labels = []\n",
    "\n",
    "pair_i = models_dict[int(1)]\n",
    "with open(pair_i[1]) as f:\n",
    "\n",
    "    model_param = json.load(f)\n",
    "    model_i=model_loader(model_param, device)# Iterate over the dataset using the sliding_window_inference method\n",
    "\n",
    "for idx in range(image_stack.shape[0]):\n",
    "\n",
    "    image_i=image_stack[idx]\n",
    "    masks_i=mask_stack[idx]\n",
    "    image_name=os.path.basename(image_files[idx])\n",
    "    print(f'shape image {image_i.shape}')\n",
    "\n",
    "    print(f'mean image {image_i.mean()}')\n",
    "    predicted_mask_np=segmentator.predict(image_i, sigmoid=True)\n",
    "    \n",
    "    tifffile.imwrite(f'../data/predictions_check/{image_name}', predicted_mask_np)\n",
    "    \n",
    "    empty_gpu_cache(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coli_mask_frame_1.tiff paired with coli_mask_frame_1.tiff\n",
      "coli_mask_frame_10.tiff paired with coli_mask_frame_10.tiff\n",
      "coli_mask_frame_101.tiff paired with coli_mask_frame_101.tiff\n",
      "coli_mask_frame_109.tiff paired with coli_mask_frame_109.tiff\n",
      "coli_mask_frame_132.tiff paired with coli_mask_frame_132.tiff\n",
      "coli_mask_frame_165.tiff paired with coli_mask_frame_165.tiff\n",
      "coli_mask_frame_166.tiff paired with coli_mask_frame_166.tiff\n",
      "coli_mask_frame_205.tiff paired with coli_mask_frame_205.tiff\n",
      "coli_mask_frame_223.tiff paired with coli_mask_frame_223.tiff\n",
      "coli_mask_frame_232.tiff paired with coli_mask_frame_232.tiff\n",
      "coli_mask_frame_274.tiff paired with coli_mask_frame_274.tiff\n",
      "coli_mask_frame_56.tiff paired with coli_mask_frame_56.tiff\n",
      "mabs_img_01.tiff paired with mabs_img_01.tiff\n",
      "mabs_img_02.tiff paired with mabs_img_02.tiff\n",
      "mabs_img_03.tiff paired with mabs_img_03.tiff\n",
      "mabs_img_04.tiff paired with mabs_img_04.tiff\n",
      "mabs_img_05.tiff paired with mabs_img_05.tiff\n",
      "mabs_img_06.tiff paired with mabs_img_06.tiff\n",
      "mabs_img_07.tiff paired with mabs_img_07.tiff\n",
      "mabs_img_08.tiff paired with mabs_img_08.tiff\n",
      "mabs_img_09.tiff paired with mabs_img_09.tiff\n",
      "mabs_img_10.tiff paired with mabs_img_10.tiff\n",
      "mabs_img_11.tiff paired with mabs_img_11.tiff\n",
      "mabs_img_12.tiff paired with mabs_img_12.tiff\n",
      "mabs_img_13.tiff paired with mabs_img_13.tiff\n",
      "mabs_img_14.tiff paired with mabs_img_14.tiff\n",
      "mabs_img_15.tiff paired with mabs_img_15.tiff\n",
      "mabs_img_16.tiff paired with mabs_img_16.tiff\n",
      "mabs_img_17.tiff paired with mabs_img_17.tiff\n",
      "mabs_img_18.tiff paired with mabs_img_18.tiff\n",
      "mabs_img_19.tiff paired with mabs_img_19.tiff\n",
      "mabs_img_20.tiff paired with mabs_img_20.tiff\n",
      "mabs_img_21.tiff paired with mabs_img_21.tiff\n",
      "mabs_img_22.tiff paired with mabs_img_22.tiff\n",
      "mabs_img_23.tiff paired with mabs_img_23.tiff\n",
      "mabs_img_24.tiff paired with mabs_img_24.tiff\n",
      "mabs_img_25.tiff paired with mabs_img_25.tiff\n",
      "mabs_img_26.tiff paired with mabs_img_26.tiff\n",
      "mabs_img_27.tiff paired with mabs_img_27.tiff\n",
      "mabs_img_28.tiff paired with mabs_img_28.tiff\n",
      "mabs_img_29.tiff paired with mabs_img_29.tiff\n",
      "mabs_img_30.tiff paired with mabs_img_30.tiff\n",
      "mabs_img_31.tiff paired with mabs_img_31.tiff\n",
      "mabs_img_32.tiff paired with mabs_img_32.tiff\n",
      "mabs_img_33.tiff paired with mabs_img_33.tiff\n",
      "mabs_img_34.tiff paired with mabs_img_34.tiff\n",
      "mabs_img_35.tiff paired with mabs_img_35.tiff\n"
     ]
    }
   ],
   "source": [
    "multi_masks_path='../data/multiclass_masks/'\n",
    "preds_path='../data/predictions_check/'\n",
    "preds_path = [os.path.join(preds_path, file) for file in os.listdir(preds_path) if file.endswith('.tiff')]\n",
    "multi_masks_path = [os.path.join(multi_masks_path, file) for file in os.listdir(multi_masks_path) if file.endswith('.tiff')]\n",
    "\n",
    "preds_path.sort()\n",
    "multi_masks_path.sort()\n",
    "\n",
    "max_width, max_height=2400, 2400\n",
    "\n",
    "for image_path, mask_path in zip(preds_path, multi_masks_path):\n",
    "\n",
    "    print(f'{os.path.basename(image_path)} paired with {os.path.basename(mask_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_images_and_masks(image_path, mask_path, max_size):\n",
    "    max_height, max_width = max_size\n",
    "\n",
    "    padded_images = []\n",
    "    padded_masks = []\n",
    "    original_dimensions = {}\n",
    "\n",
    "    for image_file, mask_file in zip(image_path, mask_path):\n",
    "        image_name = os.path.basename(mask_file)\n",
    "        image = tifffile.imread(image_file)\n",
    "        mask = tifffile.imread(mask_file)\n",
    "\n",
    "        height, width = image.shape[-2:]\n",
    "        m_height, m_width = mask.shape[-2:]\n",
    "\n",
    "        original_dimensions[image_name] = (height, width)\n",
    "\n",
    "        pad_height = max_height - height\n",
    "        pad_width = max_width - width\n",
    "\n",
    "        pad_height_m = max_height - m_height\n",
    "        pad_width_m = max_width - m_width\n",
    "\n",
    "\n",
    "        # Pad the image with zeros\n",
    "        print(f'padding {pad_height}, {pad_width}')\n",
    "        image=image[0]\n",
    "        print('image shape')\n",
    "        padded_image = np.pad(image, ((0, 0), (0, pad_height), (0, pad_width)), mode='symmetric')\n",
    "        padded_images.append(padded_image)\n",
    "        print(padded_image.shape)\n",
    "\n",
    "        # Pad the mask with zeros\n",
    "        print('mask shape')\n",
    "        padded_mask = np.pad(mask, ((0, 0), (0, pad_height_m), (0, pad_width_m)), mode='symmetric')\n",
    "        padded_masks.append(padded_mask)\n",
    "        print(padded_mask.shape)\n",
    "\n",
    "    # Convert the padded images and masks to stacks\n",
    "    image_stack = np.stack(padded_images)\n",
    "    mask_stack = np.stack(padded_masks)\n",
    "\n",
    "    return image_stack, mask_stack, original_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n",
      "padding 0, 0\n",
      "image shape\n",
      "(4, 2400, 2400)\n",
      "mask shape\n",
      "(4, 2400, 2400)\n"
     ]
    }
   ],
   "source": [
    "preds, multi_masks, _ = pad_images_and_masks(preds_path, multi_masks_path, max_size=(2400, 2400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=np.where(preds> .5, 1, 0)\n",
    "multi_masks=multi_masks/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming 'preds' and 'multi_masks' are numpy arrays\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_masks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Normalize the confusion matrix to get percentages\u001b[39;00m\n\u001b[1;32m      7\u001b[0m cm_normalized \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m cm\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:319\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    225\u001b[0m     {\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py:87\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     85\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     86\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_pred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.9/site-packages/sklearn/utils/multiclass.py:395\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(first_row):\n\u001b[1;32m    394\u001b[0m     first_row \u001b[38;5;241m=\u001b[39m first_row\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.9/site-packages/sklearn/utils/_array_api.py:307\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.9/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.9/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming 'preds' and 'multi_masks' are numpy arrays\n",
    "cm = confusion_matrix(y_true=multi_masks.flatten(), y_pred=preds.flatten())\n",
    "\n",
    "# Normalize the confusion matrix to get percentages\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Print the normalized confusion matrix\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import get_confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "#confusion_matrix = ConfusionMatrix()\n",
    "x=get_confusion_matrix(y_pred=torch.from_numpy(preds), y=torch.from_numpy(multi_masks/255))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sum = torch.sum(x, dim=0)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "cm_normalized = cm_sum.float() / cm_sum.sum(dim=1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "cm_normalized_np = cm_normalized.numpy()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm_normalized_np, annot=True, cmap='Reds')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9559,    nan, 0.9555,    nan],\n",
       "        [0.8709,    nan, 0.8656,    nan],\n",
       "        [0.9637, 0.4653, 0.9635,    nan],\n",
       "        [0.8335, 0.4505, 0.8265,    nan],\n",
       "        [0.9828,    nan, 0.9828,    nan],\n",
       "        [0.9400, 0.8100, 0.9395,    nan],\n",
       "        [0.9724,    nan, 0.9723,    nan],\n",
       "        [0.9171, 0.4758, 0.9157,    nan],\n",
       "        [0.9584,    nan, 0.9583,    nan],\n",
       "        [0.9693,    nan, 0.9692,    nan],\n",
       "        [0.9196, 0.4565, 0.9154,    nan],\n",
       "        [0.9515,    nan, 0.9508,    nan],\n",
       "        [0.8815,    nan, 0.8802, 0.8855],\n",
       "        [0.9230, 0.7372, 0.9272, 0.8897],\n",
       "        [0.9582, 0.9616, 0.9578,    nan],\n",
       "        [0.9380, 0.8936, 0.9316,    nan],\n",
       "        [0.8092, 0.6468, 0.7807, 0.8810],\n",
       "        [0.8611,    nan, 0.8591, 0.9113],\n",
       "        [0.8830, 0.7909, 0.8817,    nan],\n",
       "        [0.8473, 0.6912, 0.8517, 0.8225],\n",
       "        [0.8579, 0.8338, 0.8526, 0.9322],\n",
       "        [0.8508, 0.7809, 0.8428, 0.8979],\n",
       "        [0.8854, 0.6120, 0.8868,    nan],\n",
       "        [0.8856, 0.8677, 0.8607,    nan],\n",
       "        [0.8401, 0.6882, 0.8079, 0.8904],\n",
       "        [0.7600, 0.5917, 0.7586, 0.8085],\n",
       "        [0.9304, 0.7872, 0.9326, 0.9198],\n",
       "        [0.8610, 0.7924, 0.8523, 0.9106],\n",
       "        [0.8910, 0.7138, 0.8700, 0.9136],\n",
       "        [0.8910, 0.7866, 0.8754, 0.9324],\n",
       "        [0.8941, 0.7521, 0.9064, 0.7758],\n",
       "        [0.8897, 0.6948, 0.9121, 0.8995],\n",
       "        [0.9023,    nan, 0.8549, 0.9258],\n",
       "        [0.8455, 0.7106, 0.7845, 0.9075],\n",
       "        [0.8122, 0.7599, 0.7082, 0.8610],\n",
       "        [0.8958, 0.4562, 0.8409, 0.9228],\n",
       "        [0.8770,    nan, 0.8219, 0.9029],\n",
       "        [0.8659,    nan, 0.8250, 0.9054],\n",
       "        [0.7552, 0.6366, 0.6376, 0.8052],\n",
       "        [0.9069, 0.5245, 0.9078,    nan],\n",
       "        [0.7505, 0.6338, 0.6476, 0.8065],\n",
       "        [0.9490, 0.7327, 0.9564,    nan],\n",
       "        [0.9512, 0.9036, 0.9523,    nan],\n",
       "        [0.8942, 0.7415, 0.9032,    nan],\n",
       "        [0.8764, 0.7213, 0.8644, 0.8941],\n",
       "        [0.9216, 0.7719, 0.9207,    nan],\n",
       "        [0.9837,    nan, 0.9838,    nan]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from monai.metrics import compute_confusion_matrix_metric\n",
    "\n",
    "compute_confusion_matrix_metric('balanced accuracy', x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=np.random.choice(image_stack.shape[0], size=5, replace=False)\n",
    "\n",
    "image_stack_subset=image_stack[subset]\n",
    "mask_stack_subset=mask_stack[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=segmentator.predict(image_stack_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25, 20))  # Create a figure with 1 row and 5 columns\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(test[i, 1])\n",
    "    axes[i].axis('off')  # Remove the axis labels and ticks\n",
    "\n",
    "plt.tight_layout()  # Adjust the spacing between subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model MonaiUnet-binary-top-4\n",
      "inference time = 183.86589097976685\n",
      "average dice metric = nan\n",
      "Evaluating model MonaiUnet-binary-top-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/mzf3xz016nn449t2nlqp0k680000gn/T/ipykernel_34370/3954391690.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, iteration_df], ignore_index=True)\n",
      "/Users/santiago/switchdrive/boeck_lab_projects/Semantic_bac_segment/experiments/../src/semantic_bac_segment/segmentator.py:186: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time = 59.73834180831909\n",
      "average dice metric = 0.6324490308761597\n",
      "Evaluating model MonaiUnet-binary-top-3\n",
      "inference time = 80.85798072814941\n",
      "average dice metric = 0.6324490308761597\n",
      "Evaluating model atomai_unet-binary-top-1\n",
      "inference time = 84.26057171821594\n",
      "average dice metric = nan\n",
      "Evaluating model base_unet-binary-top-4\n",
      "inference time = 346.3613090515137\n",
      "average dice metric = nan\n",
      "Evaluating model base_unet-binary-top-5\n",
      "inference time = 371.0916347503662\n",
      "average dice metric = nan\n",
      "Evaluating model base_unet-binary-top-5\n",
      "inference time = 398.51078486442566\n",
      "average dice metric = nan\n",
      "Evaluating model atomai_unet-binary-top-1\n",
      "inference time = 84.75573468208313\n",
      "average dice metric = nan\n",
      "Evaluating model MonaiUnet-4class-4\n",
      "inference time = 277.22832703590393\n",
      "average dice metric = nan\n",
      "Evaluating model MonaiUnet-4class-4\n",
      "inference time = 277.09585881233215\n",
      "average dice metric = nan\n",
      "Evaluating model MonaiUnet-4class-3\n",
      "inference time = 84.97199201583862\n",
      "average dice metric = nan\n",
      "Evaluating model base_unet-binary-top-4\n",
      "inference time = 336.5296456813812\n",
      "average dice metric = nan\n",
      "Evaluating model MonaiUnet-binary-top-res4\n",
      "inference time = 240.36460876464844\n",
      "average dice metric = 0.6366610527038574\n",
      "Evaluating model MonaiUnet-binary-top-biasdrop.3-3\n",
      "inference time = 68.29923009872437\n",
      "average dice metric = 0.64459627866745\n",
      "Evaluating model MonaiUnet-4class-3\n",
      "inference time = 92.31707286834717\n",
      "average dice metric = nan\n",
      "Evaluating model MonaiUnet-binary-top-biasdrop3\n",
      "inference time = 66.80700278282166\n",
      "average dice metric = 0.5581502914428711\n",
      "Evaluating model MonaiUnet-binary-top-res4\n",
      "inference time = 1146.5615491867065\n",
      "average dice metric = 0.6190134286880493\n",
      "Evaluating model MonaiUnet-binary-top-bias3\n",
      "inference time = 502.9989061355591\n",
      "average dice metric = 0.630638599395752\n",
      "Evaluating model MonaiUnet-binary-top-biasdrop3\n",
      "inference time = 63.1713490486145\n",
      "average dice metric = 0.562022864818573\n",
      "Evaluating model MonaiUnet-binary-top-bias3\n",
      "inference time = 63.249006032943726\n",
      "average dice metric = 0.632483959197998\n"
     ]
    }
   ],
   "source": [
    "from semantic_bac_segment.utils import get_device\n",
    "from monai.metrics import DiceMetric, MeanIoU\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "monai_dice=DiceMetric(include_background=True, reduction=None)\n",
    "device=get_device()\n",
    "metrics_df = pd.DataFrame(columns=['model_name', 'position', 'dice_metric', 'iou_metric', 'time'])\n",
    "\n",
    "for pair_i in models_dict:\n",
    "\n",
    "    with open(pair_i[1]) as f:\n",
    "        model_param = json.load(f)\n",
    "        model_i=model_loader(model_param, device)\n",
    "    print(f'Evaluating model {model_param[\"model_name\"]}')\n",
    "    \n",
    "    segmentator = Segmentator(pair_i[0], model_graph=model_i, patch_size=256, overlap_ratio=0.25, half_precision=True)\n",
    "    tic=time.time()\n",
    "    preds=segmentator.predict(image_stack[:, 0, :,:], sigmoid=True)\n",
    "    tac=time.time()\n",
    "\n",
    "    if preds.shape[1]==4:\n",
    "        preds=preds[:, 1:, :,:]\n",
    "    \n",
    "    if preds.shape[1]==3:\n",
    "        preds=np.max(preds, axis=1)\n",
    "        preds=np.expand_dims(preds, axis=1)\n",
    "\n",
    "    preds_save=preds.copy()\n",
    "    preds_save=preds_save*255\n",
    "    tifffile.imwrite(f'../data/prediction_check4/predas_{os.path.basename(pair_i[1])[:-12]}.tiff', preds_save.astype(np.uint8))\n",
    "    monai_dice=DiceMetric(include_background=True, reduction=None)\n",
    "    monai_iou=MeanIoU(include_background=True, reduction=None)\n",
    "\n",
    "    mask_tensor=torch.from_numpy(mask_stack_binary).float()\n",
    "    preds_tensor=torch.from_numpy(preds).float()\n",
    "    \n",
    "    dice_metrics=monai_dice(mask_tensor, preds_tensor)\n",
    "    iou_metrics=monai_iou(mask_tensor, preds_tensor)\n",
    "\n",
    "    iteration_df = pd.DataFrame({\n",
    "        'model_name': [model_param['model_name']] * len(dice_metrics),\n",
    "        'position': list(range(len(dice_metrics))),\n",
    "       'dice_metric': dice_metrics.squeeze().tolist(),\n",
    "        'iou_metric': iou_metrics.squeeze().tolist(),\n",
    "        'time' : tac-tic\n",
    "    })\n",
    "    print(f'inference time = {tac-tic}')\n",
    "    print(f'average dice metric = {torch.mean(dice_metrics)}')\n",
    "    metrics_df = pd.concat([metrics_df, iteration_df], ignore_index=True)\n",
    "    metrics_df.to_csv('../data/model_metrics2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6325)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.nanmean(dice_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imwrite(os.path.join('../data/prediction_check4/',\"masks_cleaned.tiff\"), mask_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tifffile\n",
    "\n",
    "def average_tiff_stack(folder_path):\n",
    "    # Get a list of all TIFF files in the folder\n",
    "    tiff_files = glob.glob(folder_path + \"/*.tif\") + glob.glob(folder_path + \"/*.tiff\")\n",
    "    \n",
    "    # Read the TIFF files and stack them along a new axis\n",
    "    stack = []\n",
    "    for file in tiff_files:\n",
    "        image = tifffile.imread(file)\n",
    "        if image.ndim == 4:\n",
    "            image = image[:, 0, :, :]\n",
    "        print(image.shape)\n",
    "        stack.append(image)\n",
    "    #stack = np.stack(stack, axis=0)\n",
    "    \n",
    "    # Calculate the average of each pixel across the slices\n",
    "    average = np.mean(stack, axis=0)\n",
    "    \n",
    "    return average\n",
    "\n",
    "# Specify the folder path containing the TIFF files\n",
    "folder_path = '../data/prediction_check4/'\n",
    "\n",
    "# Call the function to calculate the average of the TIFF stack\n",
    "average_image = average_tiff_stack(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_image[average_image < 50] = 0\n",
    "tifffile.imwrite(os.path.join('../data/prediction_check4/',\"ensembl_image.tiff\"), average_image.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_image_binary = average_image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_image_binary[average_image_binary > 50] = 1\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_erosion\n",
    "\n",
    "def erode_roi(average_image_binary, erosion_size=1):\n",
    "    eroded_image_stack = np.zeros_like(average_image_binary)\n",
    "    \n",
    "    for i in range(average_image_binary.shape[0]):\n",
    "        image_slice = average_image_binary[i]\n",
    "        \n",
    "        # Create a structuring element for erosion\n",
    "        structure = np.ones((erosion_size, erosion_size), dtype=np.uint8)\n",
    "        \n",
    "        # Perform erosion on the current image slice\n",
    "        eroded_slice = binary_erosion(image_slice, structure)\n",
    "        \n",
    "        eroded_image_stack[i] = eroded_slice\n",
    "    \n",
    "    return eroded_image_stack\n",
    "\n",
    "# Assuming you have the average_image_binary stack with shape [slice, H, W]\n",
    "eroded_image_stack = erode_roi(average_image_binary, erosion_size=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stack=eroded_image_stack*average_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imagej_description\n",
    "\n",
    "\n",
    "labels = [os.path.basename(file) for file in image_files]\n",
    "\n",
    "# Create the ImageJ metadata\n",
    "metadata = dict(\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "\n",
    "tifffile.imwrite(os.path.join('../data/prediction_check4/',\"ensembl_image.tiff\"), \n",
    "                 mean_stack.astype(np.uint8),\n",
    "                 imagej=True,\n",
    "                 metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export individual images\n",
    "\n",
    "average_image=tifffile.imread('../data/prediction_check4/predas_MonaiUnet-4class-top-3_best.tiff')\n",
    "for i in range(image_stack.shape[0]):\n",
    "    file_i=os.path.basename(image_files[i])\n",
    "    original_height, original_width=original_dimensions[os.path.basename(file_i)]\n",
    "    print(f'origina_height: {original_height}, origina_width: {original_width}')\n",
    "    print(f'processing image {i+1} of {len(image_files)}')\n",
    "    x=average_image[i]\n",
    "    x = x[:original_height, :original_width]\n",
    "    x[x < 50] = 0\n",
    "\n",
    "    print(f'new shape x: {x.shape}')\n",
    "    tifffile.imwrite(f'../data/prediction_check4/separate_masks/{os.path.basename(file_i)}', x.astype(np.uint8))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
