{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright Â© 2022 Howard Hughes Medical Institute, \n",
    "Authored by Carsen Stringer and Marius Pachitariu.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without \n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "1. Redistributions of source code must retain the above copyright notice, \n",
    "   this list of conditions and the following disclaimer.\n",
    "\n",
    "2. Redistributions in binary form must reproduce the above copyright notice, \n",
    "   this list of conditions and the following disclaimer in the documentation \n",
    "   and/or other materials provided with the distribution.\n",
    "\n",
    "3. Neither the name of HHMI nor the names of its contributors may be used to \n",
    "   endorse or promote products derived from this software without specific \n",
    "   prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" \n",
    "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE \n",
    "ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE \n",
    "LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR \n",
    "CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF \n",
    "SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS \n",
    "INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN \n",
    "CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) \n",
    "ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE \n",
    "POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "MEDIAR Prediction uses CellPose's Gradient Flow Tracking.\n",
    "\n",
    "This code is adapted from the following codes:\n",
    "[1] https://github.com/MouseLand/cellpose/blob/main/cellpose/utils.py\n",
    "[2] https://github.com/MouseLand/cellpose/blob/main/cellpose/dynamics.py\n",
    "[3] https://github.com/MouseLand/cellpose/blob/main/cellpose/metrics.py\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import grid_sample\n",
    "import numpy as np\n",
    "import fastremap\n",
    "\n",
    "from skimage import morphology\n",
    "from scipy.ndimage import mean, find_objects\n",
    "from scipy.ndimage import maximum_filter1d\n",
    "\n",
    "torch_GPU = torch.device(\"cuda\")\n",
    "torch_CPU = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def labels_to_flows(labels, use_gpu=False, device=None, redo_flows=False):\n",
    "    \"\"\"\n",
    "    Convert labels (list of masks or flows) to flows for training model\n",
    "    \"\"\"\n",
    "\n",
    "    # Labels b x 1 x h x w\n",
    "    labels = labels.cpu().numpy().astype(np.int16)\n",
    "    nimg = len(labels)\n",
    "\n",
    "    if labels[0].ndim < 3:\n",
    "        labels = [labels[n][np.newaxis, :, :] for n in range(nimg)]\n",
    "\n",
    "    # Flows need to be recomputed\n",
    "    if labels[0].shape[0] == 1 or labels[0].ndim < 3 or redo_flows:\n",
    "        # compute flows; labels are fixed here to be unique, so they need to be passed back\n",
    "        # make sure labels are unique!\n",
    "        labels = [fastremap.renumber(label, in_place=True)[0] for label in labels]\n",
    "        veci = [\n",
    "            masks_to_flows(labels[n][0], use_gpu=use_gpu, device=device)\n",
    "            for n in range(nimg)\n",
    "        ]\n",
    "\n",
    "        # concatenate labels, distance transform, vector flows, heat (boundary and mask are computed in augmentations)\n",
    "        flows = [\n",
    "            np.concatenate((labels[n], labels[n] > 0.5, veci[n]), axis=0).astype(\n",
    "                np.float32\n",
    "            )\n",
    "            for n in range(nimg)\n",
    "        ]\n",
    "\n",
    "    return np.array(flows)\n",
    "\n",
    "\n",
    "def compute_masks(\n",
    "    dP,\n",
    "    cellprob,\n",
    "    p=None,\n",
    "    niter=200,\n",
    "    cellprob_threshold=0.4,\n",
    "    flow_threshold=0.4,\n",
    "    interp=True,\n",
    "    resize=None,\n",
    "    use_gpu=False,\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"compute masks using dynamics from dP, cellprob, and boundary\"\"\"\n",
    "\n",
    "    cp_mask = cellprob > cellprob_threshold\n",
    "    cp_mask = morphology.remove_small_holes(cp_mask, area_threshold=16)\n",
    "    cp_mask = morphology.remove_small_objects(cp_mask, min_size=16)\n",
    "\n",
    "    if np.any(cp_mask):  # mask at this point is a cell cluster binary map, not labels\n",
    "        # follow flows\n",
    "        if p is None:\n",
    "            p, inds = follow_flows(\n",
    "                dP * cp_mask / 5.0,\n",
    "                niter=niter,\n",
    "                interp=interp,\n",
    "                use_gpu=use_gpu,\n",
    "                device=device,\n",
    "            )\n",
    "            if inds is None:\n",
    "                shape = resize if resize is not None else cellprob.shape\n",
    "                mask = np.zeros(shape, np.uint16)\n",
    "                p = np.zeros((len(shape), *shape), np.uint16)\n",
    "                return mask, p\n",
    "\n",
    "        # calculate masks\n",
    "        mask = get_masks(p, iscell=cp_mask)\n",
    "        \n",
    "        # flow thresholding factored out of get_masks\n",
    "        shape0 = p.shape[1:]\n",
    "        if mask.max() > 0 and flow_threshold is not None and flow_threshold > 0:\n",
    "            # make sure labels are unique at output of get_masks\n",
    "            mask = remove_bad_flow_masks(\n",
    "                mask, dP, threshold=flow_threshold, use_gpu=use_gpu, device=device\n",
    "            )\n",
    "        else:  # nothing to compute, just make it compatible\n",
    "            shape = resize if resize is not None else cellprob.shape\n",
    "            mask = np.zeros(shape, np.uint16)\n",
    "            p = np.zeros((len(shape), *shape), np.uint16)\n",
    "\n",
    "    return mask, p\n",
    "\n",
    "\n",
    "def _extend_centers_gpu(\n",
    "    neighbors, centers, isneighbor, Ly, Lx, n_iter=200, device=torch.device(\"cuda\")\n",
    "):\n",
    "    if device is not None:\n",
    "        device = device\n",
    "    nimg = neighbors.shape[0] // 9\n",
    "    pt = torch.from_numpy(neighbors).to(device)\n",
    "    print(centers.dtype)\n",
    "    if centers.dtype == np.float64:\n",
    "        T = torch.zeros((nimg, Ly, Lx), dtype=torch.double, device=device)\n",
    "    else:\n",
    "        T = torch.zeros((nimg, Ly, Lx), dtype=torch.float32, device=device)\n",
    "    \n",
    "    meds = torch.from_numpy(centers.astype(int)).to(device).long()\n",
    "    isneigh = torch.from_numpy(isneighbor).to(device)\n",
    "    for i in range(n_iter):\n",
    "        T[:, meds[:, 0], meds[:, 1]] += 1\n",
    "        Tneigh = T[:, pt[:, :, 0], pt[:, :, 1]]\n",
    "        Tneigh *= isneigh\n",
    "        T[:, pt[0, :, 0], pt[0, :, 1]] = Tneigh.mean(axis=1)\n",
    "    del meds, isneigh, Tneigh\n",
    "    T = torch.log(1.0 + T)\n",
    "    # gradient positions\n",
    "    grads = T[:, pt[[2, 1, 4, 3], :, 0], pt[[2, 1, 4, 3], :, 1]]\n",
    "    del pt\n",
    "    dy = grads[:, 0] - grads[:, 1]\n",
    "    dx = grads[:, 2] - grads[:, 3]\n",
    "    del grads\n",
    "    mu_torch = np.stack((dy.cpu().squeeze(), dx.cpu().squeeze()), axis=-2)\n",
    "    return mu_torch\n",
    "\n",
    "\n",
    "def diameters(masks):\n",
    "    _, counts = np.unique(np.int32(masks), return_counts=True)\n",
    "    counts = counts[1:]\n",
    "    md = np.median(counts ** 0.5)\n",
    "    if np.isnan(md):\n",
    "        md = 0\n",
    "    md /= (np.pi ** 0.5) / 2\n",
    "    return md, counts ** 0.5\n",
    "\n",
    "\n",
    "def masks_to_flows_gpu(masks, device=None):\n",
    "    if device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "    Ly0, Lx0 = masks.shape\n",
    "    Ly, Lx = Ly0 + 2, Lx0 + 2\n",
    "\n",
    "    masks_padded = np.zeros((Ly, Lx), np.int64)\n",
    "    masks_padded[1:-1, 1:-1] = masks\n",
    "\n",
    "    # get mask pixel neighbors\n",
    "    y, x = np.nonzero(masks_padded)\n",
    "    neighborsY = np.stack((y, y - 1, y + 1, y, y, y - 1, y - 1, y + 1, y + 1), axis=0)\n",
    "    neighborsX = np.stack((x, x, x, x - 1, x + 1, x - 1, x + 1, x - 1, x + 1), axis=0)\n",
    "    neighbors = np.stack((neighborsY, neighborsX), axis=-1)\n",
    "\n",
    "    # get mask centers\n",
    "    slices = find_objects(masks)\n",
    "\n",
    "    centers = np.zeros((masks.max(), 2), \"int\")\n",
    "    for i, si in enumerate(slices):\n",
    "        if si is not None:\n",
    "            sr, sc = si\n",
    "\n",
    "            ly, lx = sr.stop - sr.start + 1, sc.stop - sc.start + 1\n",
    "            yi, xi = np.nonzero(masks[sr, sc] == (i + 1))\n",
    "            yi = yi.astype(np.int32) + 1  # add padding\n",
    "            xi = xi.astype(np.int32) + 1  # add padding\n",
    "            ymed = np.median(yi)\n",
    "            xmed = np.median(xi)\n",
    "            imin = np.argmin((xi - xmed) ** 2 + (yi - ymed) ** 2)\n",
    "            xmed = xi[imin]\n",
    "            ymed = yi[imin]\n",
    "            centers[i, 0] = ymed + sr.start\n",
    "            centers[i, 1] = xmed + sc.start\n",
    "\n",
    "    # get neighbor validator (not all neighbors are in same mask)\n",
    "    neighbor_masks = masks_padded[neighbors[:, :, 0], neighbors[:, :, 1]]\n",
    "    isneighbor = neighbor_masks == neighbor_masks[0]\n",
    "    ext = np.array(\n",
    "        [[sr.stop - sr.start + 1, sc.stop - sc.start + 1] for sr, sc in slices]\n",
    "    )\n",
    "    n_iter = 2 * (ext.sum(axis=1)).max()\n",
    "    # run diffusion\n",
    "    mu = _extend_centers_gpu(\n",
    "        neighbors, centers, isneighbor, Ly, Lx, n_iter=n_iter, device=device\n",
    "    )\n",
    "\n",
    "    # normalize\n",
    "    mu /= 1e-20 + (mu ** 2).sum(axis=0) ** 0.5\n",
    "\n",
    "    # put into original image\n",
    "    mu0 = np.zeros((2, Ly0, Lx0))\n",
    "    mu0[:, y - 1, x - 1] = mu\n",
    "    mu_c = np.zeros_like(mu0)\n",
    "    return mu0, mu_c\n",
    "\n",
    "\n",
    "def masks_to_flows(masks, use_gpu=False, device=None):\n",
    "    if masks.max() == 0 or (masks != 0).sum() == 1:\n",
    "        # dynamics_logger.warning('empty masks!')\n",
    "        return np.zeros((2, *masks.shape), \"float32\")\n",
    "\n",
    "    if use_gpu:\n",
    "        if use_gpu and device is None:\n",
    "            device = torch_GPU\n",
    "        elif device is None:\n",
    "            device = torch_CPU\n",
    "        masks_to_flows_device = masks_to_flows_gpu\n",
    "    else:\n",
    "        masks_to_flows_device = masks_to_flows_gpu  # Add this line\n",
    "\n",
    "    if masks.ndim == 3:\n",
    "        Lz, Ly, Lx = masks.shape\n",
    "        mu = np.zeros((3, Lz, Ly, Lx), np.float32)\n",
    "        for z in range(Lz):\n",
    "            mu0 = masks_to_flows_device(masks[z], device=device)[0]\n",
    "            mu[[1, 2], z] += mu0\n",
    "        for y in range(Ly):\n",
    "            mu0 = masks_to_flows_device(masks[:, y], device=device)[0]\n",
    "            mu[[0, 2], :, y] += mu0\n",
    "        for x in range(Lx):\n",
    "            mu0 = masks_to_flows_device(masks[:, :, x], device=device)[0]\n",
    "            mu[[0, 1], :, :, x] += mu0\n",
    "        return mu\n",
    "    elif masks.ndim == 2:\n",
    "        mu, mu_c = masks_to_flows_device(masks, device=device)\n",
    "        return mu\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"masks_to_flows only takes 2D or 3D arrays\")\n",
    "\n",
    "\n",
    "def steps2D_interp(p, dP, niter, use_gpu=False, device=None):\n",
    "    shape = dP.shape[1:]\n",
    "    if use_gpu:\n",
    "        if device is None:\n",
    "            device = torch_GPU\n",
    "        shape = (\n",
    "            np.array(shape)[[1, 0]].astype(\"float\") - 1\n",
    "        )  # Y and X dimensions (dP is 2.Ly.Lx), flipped X-1, Y-1\n",
    "        pt = (\n",
    "            torch.from_numpy(p[[1, 0]].T).float().to(device).unsqueeze(0).unsqueeze(0)\n",
    "        )  # p is n_points by 2, so pt is [1 1 2 n_points]\n",
    "        im = (\n",
    "            torch.from_numpy(dP[[1, 0]]).float().to(device).unsqueeze(0)\n",
    "        )  # covert flow numpy array to tensor on GPU, add dimension\n",
    "        # normalize pt between  0 and  1, normalize the flow\n",
    "        for k in range(2):\n",
    "            im[:, k, :, :] *= 2.0 / shape[k]\n",
    "            pt[:, :, :, k] /= shape[k]\n",
    "\n",
    "        # normalize to between -1 and 1\n",
    "        pt = pt * 2 - 1\n",
    "\n",
    "        # here is where the stepping happens\n",
    "        for t in range(niter):\n",
    "            # align_corners default is False, just added to suppress warning\n",
    "            dPt = grid_sample(im, pt, align_corners=False)\n",
    "\n",
    "            for k in range(2):  # clamp the final pixel locations\n",
    "                pt[:, :, :, k] = torch.clamp(\n",
    "                    pt[:, :, :, k] + dPt[:, k, :, :], -1.0, 1.0\n",
    "                )\n",
    "\n",
    "        # undo the normalization from before, reverse order of operations\n",
    "        pt = (pt + 1) * 0.5\n",
    "        for k in range(2):\n",
    "            pt[:, :, :, k] *= shape[k]\n",
    "\n",
    "        p = pt[:, :, :, [1, 0]].cpu().numpy().squeeze().T\n",
    "        return p\n",
    "\n",
    "    else:\n",
    "        assert print(\"ho\")\n",
    "\n",
    "\n",
    "def follow_flows(dP, mask=None, niter=200, interp=True, use_gpu=True, device=None):\n",
    "    shape = np.array(dP.shape[1:]).astype(np.int32)\n",
    "    niter = np.uint32(niter)\n",
    "\n",
    "    p = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing=\"ij\")\n",
    "    p = np.array(p).astype(np.float32)\n",
    "\n",
    "    inds = np.array(np.nonzero(np.abs(dP[0]) > 1e-3)).astype(np.int32).T\n",
    "\n",
    "    if inds.ndim < 2 or inds.shape[0] < 5:\n",
    "        return p, None\n",
    "\n",
    "    if not interp:\n",
    "        assert print(\"woo\")\n",
    "\n",
    "    else:\n",
    "        p_interp = steps2D_interp(\n",
    "            p[:, inds[:, 0], inds[:, 1]], dP, niter, use_gpu=use_gpu, device=device\n",
    "        )\n",
    "        p[:, inds[:, 0], inds[:, 1]] = p_interp\n",
    "\n",
    "    return p, inds\n",
    "\n",
    "\n",
    "def flow_error(maski, dP_net, use_gpu=False, device=None):\n",
    "    if dP_net.shape[1:] != maski.shape:\n",
    "        print(\"ERROR: net flow is not same size as predicted masks\")\n",
    "        return\n",
    "\n",
    "    # flows predicted from estimated masks\n",
    "    dP_masks = masks_to_flows(maski, use_gpu=use_gpu, device=device)\n",
    "    # difference between predicted flows vs mask flows\n",
    "    flow_errors = np.zeros(maski.max())\n",
    "    for i in range(dP_masks.shape[0]):\n",
    "        flow_errors += mean(\n",
    "            (dP_masks[i] - dP_net[i] / 5.0) ** 2,\n",
    "            maski,\n",
    "            index=np.arange(1, maski.max() + 1),\n",
    "        )\n",
    "\n",
    "    return flow_errors, dP_masks\n",
    "\n",
    "\n",
    "def remove_bad_flow_masks(masks, flows, threshold=0.4, use_gpu=False, device=None):\n",
    "    merrors, _ = flow_error(masks, flows, use_gpu, device)\n",
    "    badi = 1 + (merrors > threshold).nonzero()[0]\n",
    "    masks[np.isin(masks, badi)] = 0\n",
    "    return masks\n",
    "\n",
    "\n",
    "def get_masks(p, iscell=None, rpad=20):\n",
    "    pflows = []\n",
    "    edges = []\n",
    "    shape0 = p.shape[1:]\n",
    "    dims = len(p)\n",
    "\n",
    "    for i in range(dims):\n",
    "        pflows.append(p[i].flatten().astype(\"int32\"))\n",
    "        edges.append(np.arange(-0.5 - rpad, shape0[i] + 0.5 + rpad, 1))\n",
    "\n",
    "    h, _ = np.histogramdd(tuple(pflows), bins=edges)\n",
    "    hmax = h.copy()\n",
    "    for i in range(dims):\n",
    "        hmax = maximum_filter1d(hmax, 5, axis=i)\n",
    "\n",
    "    seeds = np.nonzero(np.logical_and(h - hmax > -1e-6, h > 10))\n",
    "    Nmax = h[seeds]\n",
    "    isort = np.argsort(Nmax)[::-1]\n",
    "    for s in seeds:\n",
    "        s = s[isort]\n",
    "\n",
    "    pix = list(np.array(seeds).T)\n",
    "\n",
    "    shape = h.shape\n",
    "    if dims == 3:\n",
    "        expand = np.nonzero(np.ones((3, 3, 3)))\n",
    "    else:\n",
    "        expand = np.nonzero(np.ones((3, 3)))\n",
    "    for e in expand:\n",
    "        e = np.expand_dims(e, 1)\n",
    "\n",
    "    for iter in range(5):\n",
    "        for k in range(len(pix)):\n",
    "            if iter == 0:\n",
    "                pix[k] = list(pix[k])\n",
    "            newpix = []\n",
    "            iin = []\n",
    "            for i, e in enumerate(expand):\n",
    "                epix = e[:, np.newaxis] + np.expand_dims(pix[k][i], 0) - 1\n",
    "                epix = epix.flatten()\n",
    "                iin.append(np.logical_and(epix >= 0, epix < shape[i]))\n",
    "                newpix.append(epix)\n",
    "            iin = np.all(tuple(iin), axis=0)\n",
    "            for p in newpix:\n",
    "                p = p[iin]\n",
    "            newpix = tuple(newpix)\n",
    "            igood = h[newpix] > 2\n",
    "            for i in range(dims):\n",
    "                pix[k][i] = newpix[i][igood]\n",
    "            if iter == 4:\n",
    "                pix[k] = tuple(pix[k])\n",
    "\n",
    "    M = np.zeros(h.shape, np.uint32)\n",
    "    for k in range(len(pix)):\n",
    "        M[pix[k]] = 1 + k\n",
    "\n",
    "    for i in range(dims):\n",
    "        pflows[i] = pflows[i] + rpad\n",
    "    M0 = M[tuple(pflows)]\n",
    "\n",
    "    # remove big masks\n",
    "    uniq, counts = fastremap.unique(M0, return_counts=True)\n",
    "    big = np.prod(shape0) * 0.9\n",
    "    bigc = uniq[counts > big]\n",
    "    if len(bigc) > 0 and (len(bigc) > 1 or bigc[0] != 0):\n",
    "        M0 = fastremap.mask(M0, bigc)\n",
    "    fastremap.renumber(M0, in_place=True)  # convenient to guarantee non-skipped labels\n",
    "    M0 = np.reshape(M0, shape0)\n",
    "    return M0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "img=tifffile.imread('../data/masks/coli_mask_frame_1.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label\n",
    "\n",
    "labeled_frame, num = label(img/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_img_tensor=torch.from_numpy(labeled_frame).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2400, 2400])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "test=labels_to_flows(batch_img_tensor, use_gpu=False, device=None, redo_flows=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 2400, 2400)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0, 3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imwrite('../data/test_flows.tiff', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
